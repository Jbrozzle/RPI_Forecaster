{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f347ba",
   "metadata": {},
   "source": [
    "# IMPORTS AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661ad4e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T20:44:21.072418Z",
     "start_time": "2022-10-14T20:44:21.058421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 100%; }\n",
       "    div#menubar-container     { width: 100%; }\n",
       "    div#maintoolbar-container { width: 100%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import dateutil\n",
    "from darts import TimeSeries\n",
    "from darts.models import ExponentialSmoothing, RegressionModel, AutoARIMA, Prophet, Theta, NBEATSModel\n",
    "from darts.metrics import mape\n",
    "import importlib\n",
    "import sys\n",
    "# from petrol_api import get_petrol_prices\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 700)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 100%; }\n",
    "    div#menubar-container     { width: 100%; }\n",
    "    div#maintoolbar-container { width: 100%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe57e300",
   "metadata": {},
   "source": [
    "PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28e2b24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T20:57:49.872167Z",
     "start_time": "2022-10-14T20:57:49.848168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Andrea\\\\Tutoring\\\\Tutoring Coding\\\\Josh'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_path=os.sep.join(os.getcwd().split(\"\\\\\")[:-1])\n",
    "project_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e02045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T20:58:15.835302Z",
     "start_time": "2022-10-14T20:58:15.821299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Andrea\\\\Tutoring\\\\Tutoring Coding\\\\Josh\\\\data'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path=os.path.join(project_path,\"data\")\n",
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ba38e",
   "metadata": {},
   "source": [
    "# CLASSES and FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3dcad2db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-14T21:48:23.041266Z",
     "start_time": "2022-10-14T21:48:21.506344Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Andrea\\\\Tutoring\\\\Tutoring Coding\\\\Josh\\\\data\\\\Weights.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 285\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    284\u001b[0m     xw\u001b[38;5;241m.\u001b[39mBook(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPI_Forecaster.xlsm\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mset_mock_caller()\n\u001b[1;32m--> 285\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [26], line 177\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    174\u001b[0m model_overrides \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel_Overrides.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    176\u001b[0m codes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(subcomponents)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCode_TS\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 177\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m descriptions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(subcomponents)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    179\u001b[0m latest_weights \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(subcomponents)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\io\\excel\\_base.py:483\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    482\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 483\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1629\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1629\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1634\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1635\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1636\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1502\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1500\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1502\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1505\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1506\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py38\\lib\\site-packages\\pandas\\io\\common.py:866\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    858\u001b[0m             handle,\n\u001b[0;32m    859\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    862\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    863\u001b[0m         )\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    869\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Andrea\\\\Tutoring\\\\Tutoring Coding\\\\Josh\\\\data\\\\Weights.xlsx'"
     ]
    }
   ],
   "source": [
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)\n",
    "\n",
    "class Subcomponent:\n",
    "\n",
    "    def __init__(self, code, description, subgroup):\n",
    "        self.short_code = code\n",
    "        self.description = description\n",
    "        self.subgroup = subgroup\n",
    "\n",
    "    def retrieve(self, timeseries_id):\n",
    "\n",
    "        api_endpoint = \"https://api.ons.gov.uk/timeseries/\"\n",
    "        api_params = {'dataset':'MM23',\n",
    "                      'time_series':timeseries_id}\n",
    "        url = (api_endpoint + '/'+api_params['time_series']+'/dataset/'+api_params['dataset']+'/data')\n",
    "\n",
    "        data = requests.get(url).json()\n",
    "        data = pd.DataFrame(pd.json_normalize(data['months']))\n",
    "        data['value'] = data['value'].astype(float)\n",
    "        data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "        data['log_ret'] = np.log(data.value) - np.log(data.value.shift(1))\n",
    "        data['Month Index'] = pd.DatetimeIndex(data['date']).month\n",
    "        data['Year Index'] = pd.DatetimeIndex(data['date']).year\n",
    "        data['pct change'] = data['value'].pct_change()\n",
    "\n",
    "        data['Easter'] = data['Year Index'].apply(dateutil.easter.easter)\n",
    "        data['Easter Month'] = pd.DatetimeIndex(data['Easter']).month\n",
    "        data['Easter Day'] = pd.DatetimeIndex(data['Easter']).day\n",
    "        data['Easter Regressor'] = data['Easter Month'] = data.apply(lambda row: int(row['Month Index']== row['Easter Month']), axis =1)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def forecast(self, data, idx):\n",
    "\n",
    "            global new_model\n",
    "            wb = xw.Book.caller()\n",
    "            idx = idx\n",
    "            df = data\n",
    "            series = TimeSeries.from_dataframe(df, 'date', 'value')\n",
    "            train, val = series[:-24], series[-24:]\n",
    "            models = [AutoARIMA(), ExponentialSmoothing()]\n",
    "            prediction_dfs = []\n",
    "            selected_models = []\n",
    "\n",
    "            BACKTESTING = False\n",
    "\n",
    "            if BACKTESTING == True:\n",
    "                backtests = [model.historical_forecasts(series=series, start=.75, forecast_horizon=12) for model in models]\n",
    "                lowest_mape = 100\n",
    "\n",
    "                for i, m in enumerate(models):\n",
    "                    err = mape(backtests[i], series)\n",
    "                    if err < lowest_mape:\n",
    "                        lowest_mape = err\n",
    "                        best_model_idx = i\n",
    "\n",
    "                model = models[best_model_idx]\n",
    "                selected_models.append(model)\n",
    "            else:\n",
    "                model_list = wb.sheets(\"Front\").range('Ak1:AK92').value\n",
    "                model = model_list[idx]\n",
    "                if model == \"AutoARIMA\":\n",
    "                    new_model = models[0]\n",
    "                else:\n",
    "                    new_model = models[1]\n",
    "\n",
    "            new_model.fit(series=series)\n",
    "            prediction = new_model.predict(27)\n",
    "            prediction_dfs.append(prediction)\n",
    "\n",
    "            #todo perform some model selection here (maybe use a bokeh GUI to perform this?)\n",
    "            #prediction_df = lowest MAPE prediction\n",
    "            #model = lowest MAPE model\n",
    "            best_prediction = prediction_dfs[0].pd_dataframe()\n",
    "            best_model = models[0]\n",
    "            mom_predictions = best_prediction.pct_change()\n",
    "\n",
    "            return best_prediction, best_model, mom_predictions, selected_models\n",
    "\n",
    "def picklecreator(dflist):\n",
    "    for i, b in enumerate(dflist):\n",
    "#         b.to_pickle(r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Pickles\\filename_{:02d}.pkl\".format(i+1))\n",
    "        b.to_pickle(os.path.join(data,\"Pickles\\\\filename_{:02d}.pkl\".format(i+1)))\n",
    "    return 1\n",
    "\n",
    "@xw.func()\n",
    "def pull_rpi_data():\n",
    "#     subcomponents = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\RPI_Subcomponents.xlsx\"\n",
    "    subcomponents = os.path.join(data_path,\"RPI_Subcomponents.xlsx\")\n",
    "    codes = pd.read_excel(subcomponents)['Code_TS']\n",
    "    descriptions = pd.read_excel(subcomponents)['Description']\n",
    "    subgroups = pd.read_excel(subcomponents)['SubGroup']\n",
    "\n",
    "    hist_data = []\n",
    "    hist_df = pd.DataFrame([], columns=descriptions)\n",
    "    wb = xw.Book.caller()\n",
    "    hist_data_sheet = wb.sheets['Hist Data']\n",
    "    # if want to get new data\n",
    "    RETRIEVE = False\n",
    "\n",
    "    if RETRIEVE == True:\n",
    "\n",
    "        for idx, code in enumerate(codes[:]):\n",
    "            code = Subcomponent(codes.iloc[idx], descriptions.iloc[idx], subgroups.iloc[idx])\n",
    "            print(code.description)\n",
    "            data = code.retrieve(code.short_code)\n",
    "            hist_data.append(data)\n",
    "\n",
    "            if idx == 0:\n",
    "                dates = data['date']\n",
    "                hist_df = pd.DataFrame(data['value'])\n",
    "                hist_df.columns = [code.description]\n",
    "                hist_df.index = dates\n",
    "\n",
    "            else:\n",
    "                new_dates = data['date']\n",
    "                s = pd.DataFrame(data['value'])\n",
    "                s.columns = [code.description]\n",
    "                s.index = new_dates\n",
    "                hist_df = pd.concat([hist_df, s], axis=1)\n",
    "\n",
    "        picklecreator(hist_data)\n",
    "\n",
    "\n",
    "    else:\n",
    "        for idx, code in enumerate(codes[:]):\n",
    "            code = Subcomponent(codes.iloc[idx], descriptions.iloc[idx], subgroups.iloc[idx])\n",
    "            print(code.description)\n",
    "#             fname = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Pickles\\filename_{:02d}.pkl\".format(idx + 1)\n",
    "            fname = os.path.join(data_path,\"Pickles\\\\filename_{:02d}.pkl\".format(idx + 1))\n",
    "            data = pd.read_pickle(fname)\n",
    "            hist_data.append(data)\n",
    "\n",
    "            # check that we want to use time series forecasting method for this subcomponent\n",
    "\n",
    "            if idx == 0:\n",
    "                dates = data['date']\n",
    "                hist_df = pd.DataFrame(data['value'])\n",
    "                hist_df.columns = [code.description]\n",
    "                hist_df.index = dates\n",
    "\n",
    "            else:\n",
    "                new_dates = data['date']\n",
    "                s = pd.DataFrame(data['value'])\n",
    "                s.columns = [code.description]\n",
    "                s.index = new_dates\n",
    "                hist_df = pd.concat([hist_df, s], axis=1)\n",
    "\n",
    "    hist_data_sheet.range('A1').value = hist_df\n",
    "\n",
    "@xw.func()\n",
    "def pull_petrol_data():\n",
    "    petrol_df, petrol_prices = get_petrol_prices()\n",
    "    #xw.Book(\"RPI_Forecaster.xlsm\").set_mock_caller()\n",
    "    wb = xw.Book.caller()\n",
    "    petrol_sheet = wb.sheets(\"Petrol\")\n",
    "    petrol_sheet.range('AA1').value = petrol_df\n",
    "\n",
    "\n",
    "@xw.func\n",
    "def main():\n",
    "\n",
    "#     xw.Book(\"RPI_Forecaster.xlsm\").set_mock_caller()\n",
    "    xw.Book(os.path.join(data_path,\"RPI_Forecaster.xlsm\")).set_mock_caller()\n",
    "    wb = xw.Book.caller()\n",
    "\n",
    "#     subcomponents = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\RPI_Subcomponents.xlsx\"\n",
    "    subcomponents = os.path.join(data_path,\"RPI_Subcomponents.xlsx\")\n",
    "#     weights = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Weights.xlsx\"\n",
    "    weights = os.path.join(data_path,\"Weights.xlsx\")\n",
    "#     model_overrides = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Model_Overrides.xlsx\"\n",
    "    model_overrides = os.path.join(data_path,\"Model_Overrides.xlsx\")\n",
    "    \n",
    "    codes = pd.read_excel(subcomponents)['Code_TS']\n",
    "    weights = pd.read_excel(weights)\n",
    "    descriptions = pd.read_excel(subcomponents)['Description']\n",
    "    latest_weights = pd.read_excel(subcomponents)['Weight']\n",
    "    subgroups = pd.read_excel(subcomponents)['SubGroup']\n",
    "    model_overrides = pd.read_excel(model_overrides)\n",
    "\n",
    "    hist_data = []\n",
    "    forecasts = []\n",
    "\n",
    "    forecast_df = pd.DataFrame([], columns=descriptions)\n",
    "    hist_df = pd.DataFrame([], columns=descriptions)\n",
    "\n",
    "    # if want to get new data\n",
    "    RETRIEVE = False\n",
    "\n",
    "\n",
    "    if RETRIEVE == True:\n",
    "\n",
    "        # get subcomponent level data and create respective forecasts\n",
    "        for idx, code in enumerate(codes[:]):\n",
    "            code = Subcomponent(codes.iloc[idx], descriptions.iloc[idx], subgroups.iloc[idx])\n",
    "            print(code.description)\n",
    "            data = code.retrieve(code.short_code)\n",
    "\n",
    "            # check that we want to use time series forecasting method for this subcomponent\n",
    "            if code.short_code not in model_overrides:\n",
    "                prediction, model, mom_forecasts, selected_models = code.forecast(data, idx)\n",
    "                # update the first forecast mom versus last available index value\n",
    "                mom_forecasts.iloc[0] = prediction.iloc[0] / data['value'].iloc[-1] - 1\n",
    "                prediction = Forecast(prediction, mom_forecasts, codes.iloc[idx],\n",
    "                                      TimeSeries.from_dataframe(prediction).time_index[:1],\n",
    "                                      TimeSeries.from_dataframe(prediction).time_index[-1:],\n",
    "                                      latest_weights.iloc[idx],\n",
    "                                      model)\n",
    "\n",
    "                hist_data.append(data)\n",
    "                forecasts.append(prediction)\n",
    "\n",
    "                mom_forecasts.append(mom_forecasts)\n",
    "\n",
    "            # otherwise pull correct forecasting model\n",
    "            else:\n",
    "                # todo generate forecasts for overriden models\n",
    "                hist_data.append(data)\n",
    "                forecasts.append(prediction)\n",
    "                mom_forecasts.append(mom_forecasts)\n",
    "                pass\n",
    "\n",
    "        picklecreator(hist_data)\n",
    "        # pd.DataFrame(hist_data).to_csv(r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\HistData.csv\")\n",
    "\n",
    "    else:\n",
    "        for idx, code in enumerate(codes[:]):\n",
    "            code = Subcomponent(codes.iloc[idx], descriptions.iloc[idx], subgroups.iloc[idx])\n",
    "            print(code.description)\n",
    "#             fname = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Pickles\\filename_{:02d}.pkl\".format(idx + 1)\n",
    "            fname = os.path.join(data_path,\"Pickles\\\\filename_{:02d}.pkl\".format(idx + 1))\n",
    "            data = pd.read_pickle(fname)\n",
    "            hist_data.append(data)\n",
    "\n",
    "            # check that we want to use time series forecasting method for this subcomponent\n",
    "            if code.short_code not in model_overrides:\n",
    "                prediction, model, mom_forecasts, selected_models = code.forecast(data, idx)\n",
    "                # update the first forecast mom versus last available index value\n",
    "                if idx == 0:\n",
    "                    forecast_df[code.description] = mom_forecasts['value']\n",
    "                    forecast_df.index = mom_forecasts.index\n",
    "                    dates = data['date']\n",
    "                    hist_df[code.description] = data['value']\n",
    "\n",
    "                else:\n",
    "                    forecast_df[code.description] = mom_forecasts['value']\n",
    "                    hist_df[code.description] = data['value']\n",
    "\n",
    "            else:\n",
    "                # todo generate forecasts for overriden models\n",
    "                hist_data.append(data)\n",
    "                forecasts.append(prediction)\n",
    "                mom_forecasts.append(mom_forecasts)\n",
    "                pass\n",
    "\n",
    "        #wb = xw.Book(r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Forecaster.xlsx\")\n",
    "        mom_sheet = wb.sheets['MoM Forecasts']\n",
    "        mom_sheet.range('A1').value = forecast_df\n",
    "        hist_df.index = dates\n",
    "        hist_data_sheet = wb.sheets['Hist Data']\n",
    "        print(hist_df)\n",
    "        #hist_data_sheet.range('A1').value = hist_df\n",
    "        front_sheet = wb.sheets['Front']\n",
    "        front_sheet.range('A40').options(transpose=True).value = selected_models\n",
    "\n",
    "@xw.func\n",
    "def hello(name):\n",
    "    return f\"Hello {name}!\"\n",
    "\n",
    "@xw.func\n",
    "def load_weights():\n",
    "#     weights = r\"C:\\Users\\joshb\\Desktop\\RPI Forecasting\\Weights.xlsx\"\n",
    "    os.path.join(data_path,\"Weights.xlsx\")\n",
    "    weights = pd.read_excel(weights)\n",
    "    weights = weights.set_index('Description')\n",
    "    weights = weights.transpose()\n",
    "    wb = xw.Book.caller()\n",
    "    weights_sheet = wb.sheets['Hist Weights']\n",
    "    weights_sheet.range(\"A1\").value = weights\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xw.Book(os.path.join(data_path,\"RPI_Forecaster.xlsm\")).set_mock_caller()\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
